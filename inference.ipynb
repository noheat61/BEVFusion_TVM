{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import models\n",
    "\n",
    "from mmengine.config import Config\n",
    "from mmengine.runner import Runner\n",
    "from mmengine.structures import InstanceData\n",
    "from mmdet3d.structures.bbox_3d.lidar_box3d import LiDARInstance3DBoxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Dataloader/Metric/BaseModel from MMDetection3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config     = \"mmdetection3d/projects/BEVFusion/configs/bevfusion_lidar-cam_voxel0075_second_secfpn_8xb4-cyclic-20e_nus-3d.py\"\n",
    "cfg = Config.fromfile(config)\n",
    "cfg.work_dir = 'mmdetection3d/work_dirs/onnx'\n",
    "\n",
    "runner = Runner.from_cfg(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = runner.val_dataloader\n",
    "evaluator = runner.val_evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Custom Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = dataloader.batch_size\n",
    "device = \"cuda\"\n",
    "\n",
    "# model = models.BEVFusionOnnxRuntimeModel(batch_size=batch_size, device=device, is_simplified=True)\n",
    "# model = models.BEVFusionTensorRTModel(batch_size=batch_size, device=device)\n",
    "model = models.BEVFusionTVMModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuscenes 기본 normalization\n",
    "\n",
    "mean = torch.tensor([123.675, 116.280, 103.530], device=device).view(3,1,1)\n",
    "std  = torch.tensor([ 58.395,  57.120,  57.375], device=device).view(3,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes_3ds = list()\n",
    "scores_3ds = list()\n",
    "labels_3ds = list()\n",
    "\n",
    "pbar = tqdm(dataloader, desc='Val')\n",
    "for e, data in enumerate(pbar):\n",
    "\n",
    "    imgs = torch.stack(data[\"inputs\"][\"img\"]).to(device)\n",
    "    imgs = (imgs - mean) / std\n",
    "\n",
    "    points = [p.to(device) for p in data[\"inputs\"][\"points\"]]\n",
    "    img_aug_matrix = np.stack([np.stack(sample.img_aug_matrix) for sample in data[\"data_samples\"]])\n",
    "    lidar_aug_matrix = np.stack([np.eye(4) for  _ in range(len(points))])\n",
    "    cam2img = np.stack([sample.cam2img for sample in data[\"data_samples\"]])\n",
    "    cam2lidar = np.stack([sample.cam2lidar for sample in data[\"data_samples\"]])\n",
    "    lidar2img = np.stack([sample.lidar2img for sample in data[\"data_samples\"]])\n",
    "\n",
    "    metas = {\n",
    "        \"img_aug_matrix\":   torch.from_numpy(img_aug_matrix.astype(np.float32)).to(device),\n",
    "        \"lidar_aug_matrix\": torch.from_numpy(lidar_aug_matrix.astype(np.float32)).to(device),\n",
    "        \"cam2img\":          torch.from_numpy(cam2img.astype(np.float32)).to(device),\n",
    "        \"cam2lidar\":        torch.from_numpy(cam2lidar.astype(np.float32)).to(device),\n",
    "        \"lidar2img\":        torch.from_numpy(lidar2img.astype(np.float32)).to(device),\n",
    "    }\n",
    "    \n",
    "    bboxes_3d, scores_3d, labels_3d = model(imgs, points, metas)\n",
    "    for B in range(len(points)):\n",
    "        bboxes_3ds.append(LiDARInstance3DBoxes(bboxes_3d[B], box_dim=9, origin=(0.5, 0.5, 0.5))),\n",
    "        scores_3ds.append(scores_3d[B]),\n",
    "        labels_3ds.append(labels_3d[B])\n",
    "\n",
    "    postfix = {key : f\"{value:.1f}ms\" for key, value in model.get_avg_latencies().items()}\n",
    "    pbar.set_postfix(postfix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataloader.dataset)):\n",
    "    data_sample = {\n",
    "        'pred_instances_3d': InstanceData(metainfo={\n",
    "            'bboxes_3d': bboxes_3ds[i].cpu(),\n",
    "            'scores_3d': scores_3ds[i].cpu(),\n",
    "            'labels_3d': labels_3ds[i].cpu(),\n",
    "        }),\n",
    "        'pred_instances': InstanceData(),\n",
    "        'sample_idx': i\n",
    "    }\n",
    "    evaluator.process(data_samples=[data_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluator.evaluate(len(dataloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
